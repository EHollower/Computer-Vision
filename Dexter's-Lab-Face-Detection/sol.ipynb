{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Concepte și Aplicații în Vederea Artificială - Tema 2\n",
    "### Detectarea și recunoașterea facială a personajelor din serialul de desene animate Laboratorul lui Dexter\n",
    "<p style='text-align: right;'> Bucă Mihnea-Vicențiu </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_data = 'crops/'\n",
    "cluster_train_data = 'clusters/'\n",
    "path_train_data = '../antrenare/'\n",
    "test_data = '../testare/' # path to test data\n",
    "npy_response = '352_Mihnea-Vicentiu_Buca/'\n",
    "npy_load_data = 'curr_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.ops import nms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]\n",
      "PyTorch version: 2.7.0.dev20250118+cpu\n",
      "OpenCV version: 4.10.0\n",
      "Numpy version: 2.1.2\n",
      "Pickle version: 4.0\n",
      "Matplotlib version: 3.9.2\n",
      "Sklearn version: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "print('Python version:', sys.version)\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('OpenCV version:', cv2.__version__)\n",
    "print('Numpy version:', np.__version__)\n",
    "print('Pickle version:', pickle.format_version)\n",
    "print('Matplotlib version:', plt.matplotlib.__version__)\n",
    "print('Sklearn version:', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +/- examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(annotations_path):\n",
    "    with open(annotations_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        classifications = []\n",
    "        for line in lines:\n",
    "            line = line.split()\n",
    "            classifications.append({\n",
    "                'image': line[0],\n",
    "                'coordinates': tuple(map(int, line[1:5])),\n",
    "                'character': line[5]\n",
    "            })\n",
    "            \n",
    "    return classifications\n",
    "\n",
    "def process_classification(classification, image_path):\n",
    "    (x1, y1, x2, y2) = classification['coordinates']\n",
    "    image = cv2.imread(image_path + classification['image'])\n",
    "    character = classification['character']\n",
    "    crop = cv2.resize(image[y1:y2, x1:x2], (64, 64))\n",
    "    return crop, character\n",
    "\n",
    "def area_bbox(bbox):\n",
    "    return (bbox[2] - bbox[0] + 1) * (bbox[3] - bbox[1] + 1)\n",
    "\n",
    "def intersection_over_union(bbox_a, bbox_b):\n",
    "    x_a = max(bbox_a[0], bbox_b[0])\n",
    "    y_a = max(bbox_a[1], bbox_b[1])\n",
    "    x_b = min(bbox_a[2], bbox_b[2])\n",
    "    y_b = min(bbox_a[3], bbox_b[3])\n",
    "\n",
    "    inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "    box_a_area = area_bbox(bbox_a)\n",
    "    box_b_area = area_bbox(bbox_b)\n",
    "\n",
    "    union_area = float(box_a_area + box_b_area - inter_area)\n",
    "    iou = inter_area / union_area if union_area != 0 else 0 \n",
    "    return iou\n",
    "\n",
    "def intersection_over_union_scaled(bbox_a, bbox_b, tresh_hold):\n",
    "    iou = intersection_over_union(bbox_a, bbox_b)\n",
    "    return iou <= tresh_hold * area_bbox(bbox_b) / area_bbox(bbox_a)\n",
    "\n",
    "def get_path(folder, index):\n",
    "    return save_train_data + folder + '/' + str(index) + '.jpg'\n",
    "\n",
    "def run_training():\n",
    "    curr_run = {\n",
    "        'dad': 0,\n",
    "        'mom': 0,\n",
    "        'dexter': 0,\n",
    "        'deedee': 0,\n",
    "        'unknown': 0,\n",
    "        'negative': 0\n",
    "    }\n",
    "\n",
    "    def clear_folders():\n",
    "        for folder in ['dad', 'mom', 'dexter', 'deedee', 'unknown', 'negative']:\n",
    "            for file in os.listdir(save_train_data + folder):\n",
    "                os.remove(save_train_data + folder + '/' + file)\n",
    "\n",
    "        for file in os.listdir(cluster_train_data):\n",
    "            os.remove(cluster_train_data + file)\n",
    "\n",
    "    def get_annotations():\n",
    "        for name in ['dad', 'mom', 'dexter', 'deedee']:\n",
    "            annotations_path = path_train_data + name + '_annotations.txt'\n",
    "            image_path = path_train_data + name + '/'\n",
    "            classifications = read_annotations(annotations_path)\n",
    "            for classification in classifications:\n",
    "                crop, character = process_classification(classification, image_path)\n",
    "                cv2.imwrite(get_path(character, curr_run[character]), crop)\n",
    "                curr_run[character] += 1\n",
    "\n",
    "    def get_clusters():\n",
    "        clusters = {\n",
    "            'dad': [],\n",
    "            'mom': [],\n",
    "            'dexter': [],\n",
    "            'deedee': [],\n",
    "            'unknown': []\n",
    "        }\n",
    "\n",
    "        for name in ['dad', 'mom', 'dexter', 'deedee']:\n",
    "            annotations_path = path_train_data + name + '_annotations.txt'\n",
    "            image_path = path_train_data + name + '/'\n",
    "            classifications = read_annotations(annotations_path)\n",
    "            for classification in classifications:\n",
    "                (x1, y1, x2, y2) = classification['coordinates']\n",
    "                _, character = process_classification(classification, image_path)\n",
    "                clusters[character].append(((x2 - x1 + 1) / (y2 - y1 + 1), y2 - y1 + 1))\n",
    "\n",
    "        for character in clusters:\n",
    "            kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "            kmeans.fit(clusters[character])\n",
    "            pickle.dump(kmeans, open(cluster_train_data + character + '_kmeans.pkl', 'wb')) \n",
    "\n",
    "    def negative_annotations():\n",
    "        for name in ['dad', 'mom', 'dexter', 'deedee']:\n",
    "            annotations_path = path_train_data + name + '_annotations.txt'\n",
    "            images_path = path_train_data + name + '/'\n",
    "\n",
    "            all_characters_in_img = {}\n",
    "            for classification in read_annotations(annotations_path):\n",
    "                image_name = classification['image']\n",
    "                (x1, y1, x2, y2) = classification['coordinates']\n",
    "\n",
    "                if image_name not in all_characters_in_img:\n",
    "                    all_characters_in_img[image_name] = []\n",
    "                all_characters_in_img[image_name].append((x1, y1, x2, y2))\n",
    "            \n",
    "\n",
    "            for (image_name, rects) in all_characters_in_img.items():\n",
    "                image = cv2.imread(images_path + image_name)\n",
    "\n",
    "                for _ in ['dad', 'mom', 'dexter', 'deedee', 'unknown']:\n",
    "                    kmeans = pickle.load(open(cluster_train_data + name + '_kmeans.pkl', 'rb'))\n",
    "                    indices = np.random.choice(len(kmeans.cluster_centers_), 4, replace=False)\n",
    "                    random_clusters = kmeans.cluster_centers_[indices]\n",
    "\n",
    "                    for (aspect_ratio, height) in random_clusters:\n",
    "                        height = int(height)\n",
    "                        width = int(aspect_ratio * height)\n",
    "\n",
    "                        if width > image.shape[1] or height > image.shape[0]:\n",
    "                            continue\n",
    "\n",
    "                        x1 = np.random.randint(0, image.shape[1] - width)\n",
    "                        y1 = np.random.randint(0, image.shape[0] - height)\n",
    "                        x2 = x1 + width\n",
    "                        y2 = y1 + height\n",
    "\n",
    "                        if x2 > image.shape[1] or y2 > image.shape[0]:\n",
    "                            continue\n",
    "                        \n",
    "                        rect_are_good = True\n",
    "                        for (x1_, y1_, x2_, y2_) in rects:\n",
    "                            if not intersection_over_union_scaled((x1, y1, x2, y2), (x1_, y1_, x2_, y2_), 0.1):\n",
    "                                rect_are_good = False\n",
    "                                break\n",
    "                        \n",
    "                        if rect_are_good: \n",
    "                            crop = cv2.resize(image[y1:y2, x1:x2], (64, 64))\n",
    "                            cv2.imwrite(get_path('negative', curr_run['negative']), crop)                             \n",
    "                            curr_run['negative'] += 1\n",
    "        \n",
    "    def save_npy_data():\n",
    "        for name in ['dad', 'mom', 'dexter', 'deedee', 'unknown', 'negative']:\n",
    "            images = []\n",
    "            print(save_train_data + name)\n",
    "            for file in os.listdir(save_train_data + name):\n",
    "                image = cv2.imread(save_train_data + name + '/' + file)\n",
    "                images.append(image)\n",
    "\n",
    "            images = np.array(images)\n",
    "            np.save(npy_load_data + name + '_images.npy', images)\n",
    "\n",
    "    clear_folders()\n",
    "    get_clusters()\n",
    "    get_annotations()\n",
    "    negative_annotations()\n",
    "    save_npy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, positive_descriptors, negative_descriptors):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Append positive samples with label 1\n",
    "        for img in positive_descriptors:\n",
    "            self.data.append(img)\n",
    "            self.labels.append(1)\n",
    "        \n",
    "        # Append negative samples with label 0\n",
    "        for img in negative_descriptors:\n",
    "            self.data.append(img)\n",
    "            self.labels.append(0)\n",
    "        \n",
    "        # Convert to tensors and normalize to [0, 1]\n",
    "        self.data = torch.tensor(self.data, dtype=torch.float32) / 255.0\n",
    "        self.data = self.data.permute(0, 3, 1, 2)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding, groups=in_channels)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            DepthwiseSeparableConv(3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            DepthwiseSeparableConv(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            DepthwiseSeparableConv(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),  # GAP\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2417f63d3b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train cnn network with data\n",
    "def get_positive_descriptors(list_positives):\n",
    "    positive_descriptors = []\n",
    "    for name in list_positives:\n",
    "        curr = np.load(npy_load_data + name + '_images.npy')\n",
    "        positive_descriptors.extend(curr) \n",
    "    \n",
    "    return positive_descriptors\n",
    "\n",
    "def get_negative_descriptors(list_negatives):\n",
    "    negative_descriptors = []\n",
    "    for name in list_negatives:\n",
    "        curr = np.load(npy_load_data + name + '_images.npy')\n",
    "        negative_descriptors.extend(curr)\n",
    "    \n",
    "    return negative_descriptors\n",
    "\n",
    "def train_classifier(name, list_positives, list_negatives):\n",
    "    # Get data\n",
    "    print(\"Loading data...\")\n",
    "    positive_descriptors = get_positive_descriptors(list_positives)\n",
    "    negative_descriptors = get_negative_descriptors(list_negatives)\n",
    "    print(\"Data loaded\")\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    print(\"Creating dataset and dataloader...\")\n",
    "    dataset = Dataset(positive_descriptors, negative_descriptors)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    print(\"Initializing model, loss function, and optimizer...\")\n",
    "    model = CNN()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    # Training loop\n",
    "    print(\"Training model...\")\n",
    "    epochs = 5\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), f'{name}_cnn.pth')\n",
    "    print(f'Model saved as {name}_cnn.pth')\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "# train_classifier(\"all_faces_v2\", ['dad', 'mom', 'dexter', 'deedee', 'unknown'], ['negative'])\n",
    "# train_classifier(\"dad\", ['dad'], ['mom', 'dexter', 'deedee', 'unknown', 'negative'])\n",
    "# train_classifier(\"deedee\", ['deedee'], ['dad', 'mom', 'dexter', 'unknown', 'negative'])\n",
    "# train_classifier(\"dexter\", ['dexter'], ['dad', 'mom', 'deedee', 'unknown', 'negative'])\n",
    "# train_classifier(\"mom\", ['mom'], ['dad', 'dexter', 'deedee', 'unknown', 'negative'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_completely_overlapped(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    return (x1 <= x3 and y1 <= y3 and x2 >= x4 and y2 >= y4) or \\\n",
    "              (x3 <= x1 and y3 <= y1 and x4 >= x2 and y4 >= y2)\n",
    "\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1] + 1, step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0] + 1, step_size):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "def filter_boxes(best_results, iou_threshold=0.25):\n",
    "    bboxes = [result[0] for result in best_results]\n",
    "    scores = [result[1] for result in best_results]\n",
    "    keep_indices = []\n",
    "    \n",
    "    for i, bbox1 in enumerate(bboxes):\n",
    "        keep = True\n",
    "        for j, bbox2 in enumerate(bboxes):\n",
    "            if i != j and (intersection_over_union(bbox1, bbox2) > iou_threshold or is_completely_overlapped(bbox1, bbox2)):\n",
    "                if scores[i] < scores[j]:\n",
    "                    keep = False\n",
    "                    break\n",
    "        if keep:\n",
    "            keep_indices.append(i)\n",
    "    return [best_results[idx] for idx in keep_indices]\n",
    "\n",
    "def detect_faces_best_aspect_ratios(test_data, model, model_name, cluster_train_data, task=\"task1\", step_size=16, threshold=0.90):\n",
    "    face_recognition_results = []\n",
    "    \n",
    "    # Preload all clusters\n",
    "    clusters = {name: pickle.load(open(cluster_train_data + name + '_kmeans.pkl', 'rb'))\n",
    "                for name in ['dad', 'mom', 'dexter', 'deedee', 'unknown']}\n",
    "\n",
    "\n",
    "    all_cluster_centers = []\n",
    "    for name, kmeans in clusters.items():\n",
    "        all_cluster_centers.extend(kmeans.cluster_centers_)\n",
    "    \n",
    "    all_cluster_centers = np.vstack(all_cluster_centers)\n",
    "\n",
    "    min_len = min(20, all_cluster_centers.shape[0])\n",
    "\n",
    "    detections_for_model = []\n",
    "    file_names_for_model = []\n",
    "    scores_for_model = []\n",
    "\n",
    "    for image_path in os.listdir(test_data):\n",
    "        image = cv2.imread(test_data + image_path)\n",
    "        best_results = []\n",
    "\n",
    "        random_indices = np.random.choice(all_cluster_centers.shape[0], min_len, replace=False)\n",
    "\n",
    "        aspect_ratios = all_cluster_centers[random_indices, 0]\n",
    "        heights = all_cluster_centers[random_indices, 1]\n",
    "\n",
    "        for aspect_ratio, height in zip(aspect_ratios, heights):\n",
    "            window_height = int(height)\n",
    "            window_width = int(aspect_ratio * height)\n",
    "            window_size = (window_width, window_height)\n",
    "\n",
    "            batch_windows = []\n",
    "            batch_coords = []\n",
    "\n",
    "            for x, y, window in sliding_window(image, step_size, window_size):\n",
    "                if x + window_width > image.shape[1] or y + window_height > image.shape[0]:\n",
    "                    continue\n",
    "\n",
    "                resized_window = cv2.resize(window, (64, 64))\n",
    "                resized_window = torch.tensor(resized_window, dtype=torch.float32) / 255.0\n",
    "                resized_window = resized_window.permute(2, 0, 1)\n",
    "                batch_windows.append(resized_window)\n",
    "                batch_coords.append((x, y, x + window_width, y + window_height))\n",
    "\n",
    "            if batch_windows:\n",
    "                batch_windows = torch.stack(batch_windows)\n",
    "                with torch.no_grad():\n",
    "                    probs = model(batch_windows).squeeze().tolist()\n",
    "                \n",
    "                best_results.extend([(batch_coords[i], probs[i]) for i in range(len(batch_windows)) if probs[i] > threshold])\n",
    "        \n",
    "        if len(best_results) > 0:\n",
    "            # Apply NMS\n",
    "            bboxes, scores = zip(*best_results)\n",
    "            bboxes = torch.tensor(bboxes, dtype=torch.float32)\n",
    "            scores = torch.tensor(scores, dtype=torch.float32)\n",
    "            indices = nms(bboxes, scores, 0.25)\n",
    "            best_results = [(bboxes[idx].int().tolist(), scores[idx].item()) for idx in indices]\n",
    "\n",
    "            # Filter results\n",
    "            best_results = filter_boxes(best_results, 0.25)\n",
    "\n",
    "\n",
    "            # Draw results\n",
    "            for bbox, _ in best_results:\n",
    "                detections_for_model.append(bbox)\n",
    "                file_names_for_model.append(image_path)\n",
    "                scores_for_model.append(_)\n",
    "\n",
    "                # x1, y1, x2, y2 = bbox\n",
    "                # cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "            # face_recognition_results.append(image)\n",
    "\n",
    "        print(\"Processed\", image_path)\n",
    "    \n",
    "    np.save(npy_response + f'{task}/detections_{model_name}.npy', detections_for_model)\n",
    "    np.save(npy_response + f'{task}/file_names_{model_name}.npy', file_names_for_model)\n",
    "    np.save(npy_response + f'{task}/scores_{model_name}.npy', scores_for_model)\n",
    "    # return face_recognition_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting all faces...\n",
      "Processed 001.jpg\n",
      "Processed 002.jpg\n",
      "Processed 003.jpg\n",
      "Processed 004.jpg\n",
      "Processed 005.jpg\n",
      "Processed 006.jpg\n",
      "Processed 007.jpg\n",
      "Processed 008.jpg\n",
      "Processed 009.jpg\n",
      "Processed 010.jpg\n",
      "Processed 011.jpg\n",
      "Processed 012.jpg\n",
      "Processed 013.jpg\n",
      "Processed 014.jpg\n",
      "Processed 015.jpg\n",
      "Processed 016.jpg\n",
      "Processed 017.jpg\n",
      "Processed 018.jpg\n",
      "Processed 019.jpg\n",
      "Processed 020.jpg\n",
      "Processed 021.jpg\n",
      "Processed 022.jpg\n",
      "Processed 023.jpg\n",
      "Processed 024.jpg\n",
      "Processed 025.jpg\n",
      "Processed 026.jpg\n",
      "Processed 027.jpg\n",
      "Processed 028.jpg\n",
      "Processed 029.jpg\n",
      "Processed 030.jpg\n",
      "Processed 031.jpg\n",
      "Processed 032.jpg\n",
      "Processed 033.jpg\n",
      "Processed 034.jpg\n",
      "Processed 035.jpg\n",
      "Processed 036.jpg\n",
      "Processed 037.jpg\n",
      "Processed 038.jpg\n",
      "Processed 039.jpg\n",
      "Processed 040.jpg\n",
      "Processed 041.jpg\n",
      "Processed 042.jpg\n",
      "Processed 043.jpg\n",
      "Processed 044.jpg\n",
      "Processed 045.jpg\n",
      "Processed 046.jpg\n",
      "Processed 047.jpg\n",
      "Processed 048.jpg\n",
      "Processed 049.jpg\n",
      "Processed 050.jpg\n",
      "Processed 051.jpg\n",
      "Processed 052.jpg\n",
      "Processed 053.jpg\n",
      "Processed 054.jpg\n",
      "Processed 055.jpg\n",
      "Processed 056.jpg\n",
      "Processed 057.jpg\n",
      "Processed 058.jpg\n",
      "Processed 059.jpg\n",
      "Processed 060.jpg\n",
      "Processed 061.jpg\n",
      "Processed 062.jpg\n",
      "Processed 063.jpg\n",
      "Processed 064.jpg\n",
      "Processed 065.jpg\n",
      "Processed 066.jpg\n",
      "Processed 067.jpg\n",
      "Processed 068.jpg\n",
      "Processed 069.jpg\n",
      "Processed 070.jpg\n",
      "Processed 071.jpg\n",
      "Processed 072.jpg\n",
      "Processed 073.jpg\n",
      "Processed 074.jpg\n",
      "Processed 075.jpg\n",
      "Processed 076.jpg\n",
      "Processed 077.jpg\n",
      "Processed 078.jpg\n",
      "Processed 079.jpg\n",
      "Processed 080.jpg\n",
      "Processed 081.jpg\n",
      "Processed 082.jpg\n",
      "Processed 083.jpg\n",
      "Processed 084.jpg\n",
      "Processed 085.jpg\n",
      "Processed 086.jpg\n",
      "Processed 087.jpg\n",
      "Processed 088.jpg\n",
      "Processed 089.jpg\n",
      "Processed 090.jpg\n",
      "Processed 091.jpg\n",
      "Processed 092.jpg\n",
      "Processed 093.jpg\n",
      "Processed 094.jpg\n",
      "Processed 095.jpg\n",
      "Processed 096.jpg\n",
      "Processed 097.jpg\n",
      "Processed 098.jpg\n",
      "Processed 099.jpg\n",
      "Processed 100.jpg\n",
      "Processed 101.jpg\n",
      "Processed 102.jpg\n",
      "Processed 103.jpg\n",
      "Processed 104.jpg\n",
      "Processed 105.jpg\n",
      "Processed 106.jpg\n",
      "Processed 107.jpg\n",
      "Processed 108.jpg\n",
      "Processed 109.jpg\n",
      "Processed 110.jpg\n",
      "Processed 111.jpg\n",
      "Processed 112.jpg\n",
      "Processed 113.jpg\n",
      "Processed 114.jpg\n",
      "Processed 115.jpg\n",
      "Processed 116.jpg\n",
      "Processed 117.jpg\n",
      "Processed 118.jpg\n",
      "Processed 119.jpg\n",
      "Processed 120.jpg\n",
      "Processed 121.jpg\n",
      "Processed 122.jpg\n",
      "Processed 123.jpg\n",
      "Processed 124.jpg\n",
      "Processed 125.jpg\n",
      "Processed 126.jpg\n",
      "Processed 127.jpg\n",
      "Processed 128.jpg\n",
      "Processed 129.jpg\n",
      "Processed 130.jpg\n",
      "Processed 131.jpg\n",
      "Processed 132.jpg\n",
      "Processed 133.jpg\n",
      "Processed 134.jpg\n",
      "Processed 135.jpg\n",
      "Processed 136.jpg\n",
      "Processed 137.jpg\n",
      "Processed 138.jpg\n",
      "Processed 139.jpg\n",
      "Processed 140.jpg\n",
      "Processed 141.jpg\n",
      "Processed 142.jpg\n",
      "Processed 143.jpg\n",
      "Processed 144.jpg\n",
      "Processed 145.jpg\n",
      "Processed 146.jpg\n",
      "Processed 147.jpg\n",
      "Processed 148.jpg\n",
      "Processed 149.jpg\n",
      "Processed 150.jpg\n",
      "Processed 151.jpg\n",
      "Processed 152.jpg\n",
      "Processed 153.jpg\n",
      "Processed 154.jpg\n",
      "Processed 155.jpg\n",
      "Processed 156.jpg\n",
      "Processed 157.jpg\n",
      "Processed 158.jpg\n",
      "Processed 159.jpg\n",
      "Processed 160.jpg\n",
      "Processed 161.jpg\n",
      "Processed 162.jpg\n",
      "Processed 163.jpg\n",
      "Processed 164.jpg\n",
      "Processed 165.jpg\n",
      "Processed 166.jpg\n",
      "Processed 167.jpg\n",
      "Processed 168.jpg\n",
      "Processed 169.jpg\n",
      "Processed 170.jpg\n",
      "Processed 171.jpg\n",
      "Processed 172.jpg\n",
      "Processed 173.jpg\n",
      "Processed 174.jpg\n",
      "Processed 175.jpg\n",
      "Processed 176.jpg\n",
      "Processed 177.jpg\n",
      "Processed 178.jpg\n",
      "Processed 179.jpg\n",
      "Processed 180.jpg\n",
      "Processed 181.jpg\n",
      "Processed 182.jpg\n",
      "Processed 183.jpg\n",
      "Processed 184.jpg\n",
      "Processed 185.jpg\n",
      "Processed 186.jpg\n",
      "Processed 187.jpg\n",
      "Processed 188.jpg\n",
      "Processed 189.jpg\n",
      "Processed 190.jpg\n",
      "Processed 191.jpg\n",
      "Processed 192.jpg\n",
      "Processed 193.jpg\n",
      "Processed 194.jpg\n",
      "Processed 195.jpg\n",
      "Processed 196.jpg\n",
      "Processed 197.jpg\n",
      "Processed 198.jpg\n",
      "Processed 199.jpg\n",
      "Processed 200.jpg\n"
     ]
    }
   ],
   "source": [
    "def detect_all_faces():\n",
    "    print(\"Detecting all faces...\")\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(\"all_faces_cnn.pth\"))\n",
    "    model.eval()\n",
    "    detect_faces_best_aspect_ratios(test_data, model, 'all_faces', cluster_train_data, threshold=0.90, task=\"task1\")\n",
    "   \n",
    "detect_all_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning set for dad\n",
      "Processed 001.jpg\n",
      "Processed 002.jpg\n",
      "Processed 003.jpg\n",
      "Processed 004.jpg\n",
      "Processed 005.jpg\n",
      "Processed 006.jpg\n",
      "Processed 007.jpg\n",
      "Processed 008.jpg\n",
      "Processed 009.jpg\n",
      "Processed 010.jpg\n",
      "Processed 011.jpg\n",
      "Processed 012.jpg\n",
      "Processed 013.jpg\n",
      "Processed 014.jpg\n",
      "Processed 015.jpg\n",
      "Processed 016.jpg\n",
      "Processed 017.jpg\n",
      "Processed 018.jpg\n",
      "Processed 019.jpg\n",
      "Processed 020.jpg\n",
      "Processed 021.jpg\n",
      "Processed 022.jpg\n",
      "Processed 023.jpg\n",
      "Processed 024.jpg\n",
      "Processed 025.jpg\n",
      "Processed 026.jpg\n",
      "Processed 027.jpg\n",
      "Processed 028.jpg\n",
      "Processed 029.jpg\n",
      "Processed 030.jpg\n",
      "Processed 031.jpg\n",
      "Processed 032.jpg\n",
      "Processed 033.jpg\n",
      "Processed 034.jpg\n",
      "Processed 035.jpg\n",
      "Processed 036.jpg\n",
      "Processed 037.jpg\n",
      "Processed 038.jpg\n",
      "Processed 039.jpg\n",
      "Processed 040.jpg\n",
      "Processed 041.jpg\n",
      "Processed 042.jpg\n",
      "Processed 043.jpg\n",
      "Processed 044.jpg\n",
      "Processed 045.jpg\n",
      "Processed 046.jpg\n",
      "Processed 047.jpg\n",
      "Processed 048.jpg\n",
      "Processed 049.jpg\n",
      "Processed 050.jpg\n",
      "Processed 051.jpg\n",
      "Processed 052.jpg\n",
      "Processed 053.jpg\n",
      "Processed 054.jpg\n",
      "Processed 055.jpg\n",
      "Processed 056.jpg\n",
      "Processed 057.jpg\n",
      "Processed 058.jpg\n",
      "Processed 059.jpg\n",
      "Processed 060.jpg\n",
      "Processed 061.jpg\n",
      "Processed 062.jpg\n",
      "Processed 063.jpg\n",
      "Processed 064.jpg\n",
      "Processed 065.jpg\n",
      "Processed 066.jpg\n",
      "Processed 067.jpg\n",
      "Processed 068.jpg\n",
      "Processed 069.jpg\n",
      "Processed 070.jpg\n",
      "Processed 071.jpg\n",
      "Processed 072.jpg\n",
      "Processed 073.jpg\n",
      "Processed 074.jpg\n",
      "Processed 075.jpg\n",
      "Processed 076.jpg\n",
      "Processed 077.jpg\n",
      "Processed 078.jpg\n",
      "Processed 079.jpg\n",
      "Processed 080.jpg\n",
      "Processed 081.jpg\n",
      "Processed 082.jpg\n",
      "Processed 083.jpg\n",
      "Processed 084.jpg\n",
      "Processed 085.jpg\n",
      "Processed 086.jpg\n",
      "Processed 087.jpg\n",
      "Processed 088.jpg\n",
      "Processed 089.jpg\n",
      "Processed 090.jpg\n",
      "Processed 091.jpg\n",
      "Processed 092.jpg\n",
      "Processed 093.jpg\n",
      "Processed 094.jpg\n",
      "Processed 095.jpg\n",
      "Processed 096.jpg\n",
      "Processed 097.jpg\n",
      "Processed 098.jpg\n",
      "Processed 099.jpg\n",
      "Processed 100.jpg\n",
      "Processed 101.jpg\n",
      "Processed 102.jpg\n",
      "Processed 103.jpg\n",
      "Processed 104.jpg\n",
      "Processed 105.jpg\n",
      "Processed 106.jpg\n",
      "Processed 107.jpg\n",
      "Processed 108.jpg\n",
      "Processed 109.jpg\n",
      "Processed 110.jpg\n",
      "Processed 111.jpg\n",
      "Processed 112.jpg\n",
      "Processed 113.jpg\n",
      "Processed 114.jpg\n",
      "Processed 115.jpg\n",
      "Processed 116.jpg\n",
      "Processed 117.jpg\n",
      "Processed 118.jpg\n",
      "Processed 119.jpg\n",
      "Processed 120.jpg\n",
      "Processed 121.jpg\n",
      "Processed 122.jpg\n",
      "Processed 123.jpg\n",
      "Processed 124.jpg\n",
      "Processed 125.jpg\n",
      "Processed 126.jpg\n",
      "Processed 127.jpg\n",
      "Processed 128.jpg\n",
      "Processed 129.jpg\n",
      "Processed 130.jpg\n",
      "Processed 131.jpg\n",
      "Processed 132.jpg\n",
      "Processed 133.jpg\n",
      "Processed 134.jpg\n",
      "Processed 135.jpg\n",
      "Processed 136.jpg\n",
      "Processed 137.jpg\n",
      "Processed 138.jpg\n",
      "Processed 139.jpg\n",
      "Processed 140.jpg\n",
      "Processed 141.jpg\n",
      "Processed 142.jpg\n",
      "Processed 143.jpg\n",
      "Processed 144.jpg\n",
      "Processed 145.jpg\n",
      "Processed 146.jpg\n",
      "Processed 147.jpg\n",
      "Processed 148.jpg\n",
      "Processed 149.jpg\n",
      "Processed 150.jpg\n",
      "Processed 151.jpg\n",
      "Processed 152.jpg\n",
      "Processed 153.jpg\n",
      "Processed 154.jpg\n",
      "Processed 155.jpg\n",
      "Processed 156.jpg\n",
      "Processed 157.jpg\n",
      "Processed 158.jpg\n",
      "Processed 159.jpg\n",
      "Processed 160.jpg\n",
      "Processed 161.jpg\n",
      "Processed 162.jpg\n",
      "Processed 163.jpg\n",
      "Processed 164.jpg\n",
      "Processed 165.jpg\n",
      "Processed 166.jpg\n",
      "Processed 167.jpg\n",
      "Processed 168.jpg\n",
      "Processed 169.jpg\n",
      "Processed 170.jpg\n",
      "Processed 171.jpg\n",
      "Processed 172.jpg\n",
      "Processed 173.jpg\n",
      "Processed 174.jpg\n",
      "Processed 175.jpg\n",
      "Processed 176.jpg\n",
      "Processed 177.jpg\n",
      "Processed 178.jpg\n",
      "Processed 179.jpg\n",
      "Processed 180.jpg\n",
      "Processed 181.jpg\n",
      "Processed 182.jpg\n",
      "Processed 183.jpg\n",
      "Processed 184.jpg\n",
      "Processed 185.jpg\n",
      "Processed 186.jpg\n",
      "Processed 187.jpg\n",
      "Processed 188.jpg\n",
      "Processed 189.jpg\n",
      "Processed 190.jpg\n",
      "Processed 191.jpg\n",
      "Processed 192.jpg\n",
      "Processed 193.jpg\n",
      "Processed 194.jpg\n",
      "Processed 195.jpg\n",
      "Processed 196.jpg\n",
      "Processed 197.jpg\n",
      "Processed 198.jpg\n",
      "Processed 199.jpg\n",
      "Processed 200.jpg\n",
      "Scanning set for deedee\n",
      "Processed 001.jpg\n",
      "Processed 002.jpg\n",
      "Processed 003.jpg\n",
      "Processed 004.jpg\n",
      "Processed 005.jpg\n",
      "Processed 006.jpg\n",
      "Processed 007.jpg\n",
      "Processed 008.jpg\n",
      "Processed 009.jpg\n",
      "Processed 010.jpg\n",
      "Processed 011.jpg\n",
      "Processed 012.jpg\n",
      "Processed 013.jpg\n",
      "Processed 014.jpg\n",
      "Processed 015.jpg\n",
      "Processed 016.jpg\n",
      "Processed 017.jpg\n",
      "Processed 018.jpg\n",
      "Processed 019.jpg\n",
      "Processed 020.jpg\n",
      "Processed 021.jpg\n",
      "Processed 022.jpg\n",
      "Processed 023.jpg\n",
      "Processed 024.jpg\n",
      "Processed 025.jpg\n",
      "Processed 026.jpg\n",
      "Processed 027.jpg\n",
      "Processed 028.jpg\n",
      "Processed 029.jpg\n",
      "Processed 030.jpg\n",
      "Processed 031.jpg\n",
      "Processed 032.jpg\n",
      "Processed 033.jpg\n",
      "Processed 034.jpg\n",
      "Processed 035.jpg\n",
      "Processed 036.jpg\n",
      "Processed 037.jpg\n",
      "Processed 038.jpg\n",
      "Processed 039.jpg\n",
      "Processed 040.jpg\n",
      "Processed 041.jpg\n",
      "Processed 042.jpg\n",
      "Processed 043.jpg\n",
      "Processed 044.jpg\n",
      "Processed 045.jpg\n",
      "Processed 046.jpg\n",
      "Processed 047.jpg\n",
      "Processed 048.jpg\n",
      "Processed 049.jpg\n",
      "Processed 050.jpg\n",
      "Processed 051.jpg\n",
      "Processed 052.jpg\n",
      "Processed 053.jpg\n",
      "Processed 054.jpg\n",
      "Processed 055.jpg\n",
      "Processed 056.jpg\n",
      "Processed 057.jpg\n",
      "Processed 058.jpg\n",
      "Processed 059.jpg\n",
      "Processed 060.jpg\n",
      "Processed 061.jpg\n",
      "Processed 062.jpg\n",
      "Processed 063.jpg\n",
      "Processed 064.jpg\n",
      "Processed 065.jpg\n",
      "Processed 066.jpg\n",
      "Processed 067.jpg\n",
      "Processed 068.jpg\n",
      "Processed 069.jpg\n",
      "Processed 070.jpg\n",
      "Processed 071.jpg\n",
      "Processed 072.jpg\n",
      "Processed 073.jpg\n",
      "Processed 074.jpg\n",
      "Processed 075.jpg\n",
      "Processed 076.jpg\n",
      "Processed 077.jpg\n",
      "Processed 078.jpg\n",
      "Processed 079.jpg\n",
      "Processed 080.jpg\n",
      "Processed 081.jpg\n",
      "Processed 082.jpg\n",
      "Processed 083.jpg\n",
      "Processed 084.jpg\n",
      "Processed 085.jpg\n",
      "Processed 086.jpg\n",
      "Processed 087.jpg\n",
      "Processed 088.jpg\n",
      "Processed 089.jpg\n",
      "Processed 090.jpg\n",
      "Processed 091.jpg\n",
      "Processed 092.jpg\n",
      "Processed 093.jpg\n",
      "Processed 094.jpg\n",
      "Processed 095.jpg\n",
      "Processed 096.jpg\n",
      "Processed 097.jpg\n",
      "Processed 098.jpg\n",
      "Processed 099.jpg\n",
      "Processed 100.jpg\n",
      "Processed 101.jpg\n",
      "Processed 102.jpg\n",
      "Processed 103.jpg\n",
      "Processed 104.jpg\n",
      "Processed 105.jpg\n",
      "Processed 106.jpg\n",
      "Processed 107.jpg\n",
      "Processed 108.jpg\n",
      "Processed 109.jpg\n",
      "Processed 110.jpg\n",
      "Processed 111.jpg\n",
      "Processed 112.jpg\n",
      "Processed 113.jpg\n",
      "Processed 114.jpg\n",
      "Processed 115.jpg\n",
      "Processed 116.jpg\n",
      "Processed 117.jpg\n",
      "Processed 118.jpg\n",
      "Processed 119.jpg\n",
      "Processed 120.jpg\n",
      "Processed 121.jpg\n",
      "Processed 122.jpg\n",
      "Processed 123.jpg\n",
      "Processed 124.jpg\n",
      "Processed 125.jpg\n",
      "Processed 126.jpg\n",
      "Processed 127.jpg\n",
      "Processed 128.jpg\n",
      "Processed 129.jpg\n",
      "Processed 130.jpg\n",
      "Processed 131.jpg\n",
      "Processed 132.jpg\n",
      "Processed 133.jpg\n",
      "Processed 134.jpg\n",
      "Processed 135.jpg\n",
      "Processed 136.jpg\n",
      "Processed 137.jpg\n",
      "Processed 138.jpg\n",
      "Processed 139.jpg\n",
      "Processed 140.jpg\n",
      "Processed 141.jpg\n",
      "Processed 142.jpg\n",
      "Processed 143.jpg\n",
      "Processed 144.jpg\n",
      "Processed 145.jpg\n",
      "Processed 146.jpg\n",
      "Processed 147.jpg\n",
      "Processed 148.jpg\n",
      "Processed 149.jpg\n",
      "Processed 150.jpg\n",
      "Processed 151.jpg\n",
      "Processed 152.jpg\n",
      "Processed 153.jpg\n",
      "Processed 154.jpg\n",
      "Processed 155.jpg\n",
      "Processed 156.jpg\n",
      "Processed 157.jpg\n",
      "Processed 158.jpg\n",
      "Processed 159.jpg\n",
      "Processed 160.jpg\n",
      "Processed 161.jpg\n",
      "Processed 162.jpg\n",
      "Processed 163.jpg\n",
      "Processed 164.jpg\n",
      "Processed 165.jpg\n",
      "Processed 166.jpg\n",
      "Processed 167.jpg\n",
      "Processed 168.jpg\n",
      "Processed 169.jpg\n",
      "Processed 170.jpg\n",
      "Processed 171.jpg\n",
      "Processed 172.jpg\n",
      "Processed 173.jpg\n",
      "Processed 174.jpg\n",
      "Processed 175.jpg\n",
      "Processed 176.jpg\n",
      "Processed 177.jpg\n",
      "Processed 178.jpg\n",
      "Processed 179.jpg\n",
      "Processed 180.jpg\n",
      "Processed 181.jpg\n",
      "Processed 182.jpg\n",
      "Processed 183.jpg\n",
      "Processed 184.jpg\n",
      "Processed 185.jpg\n",
      "Processed 186.jpg\n",
      "Processed 187.jpg\n",
      "Processed 188.jpg\n",
      "Processed 189.jpg\n",
      "Processed 190.jpg\n",
      "Processed 191.jpg\n",
      "Processed 192.jpg\n",
      "Processed 193.jpg\n",
      "Processed 194.jpg\n",
      "Processed 195.jpg\n",
      "Processed 196.jpg\n",
      "Processed 197.jpg\n",
      "Processed 198.jpg\n",
      "Processed 199.jpg\n",
      "Processed 200.jpg\n",
      "Scanning set for dexter\n",
      "Processed 001.jpg\n",
      "Processed 002.jpg\n",
      "Processed 003.jpg\n",
      "Processed 004.jpg\n",
      "Processed 005.jpg\n",
      "Processed 006.jpg\n",
      "Processed 007.jpg\n",
      "Processed 008.jpg\n",
      "Processed 009.jpg\n",
      "Processed 010.jpg\n",
      "Processed 011.jpg\n",
      "Processed 012.jpg\n",
      "Processed 013.jpg\n",
      "Processed 014.jpg\n",
      "Processed 015.jpg\n",
      "Processed 016.jpg\n",
      "Processed 017.jpg\n",
      "Processed 018.jpg\n",
      "Processed 019.jpg\n",
      "Processed 020.jpg\n",
      "Processed 021.jpg\n",
      "Processed 022.jpg\n",
      "Processed 023.jpg\n",
      "Processed 024.jpg\n",
      "Processed 025.jpg\n",
      "Processed 026.jpg\n",
      "Processed 027.jpg\n",
      "Processed 028.jpg\n",
      "Processed 029.jpg\n",
      "Processed 030.jpg\n",
      "Processed 031.jpg\n",
      "Processed 032.jpg\n",
      "Processed 033.jpg\n",
      "Processed 034.jpg\n",
      "Processed 035.jpg\n",
      "Processed 036.jpg\n",
      "Processed 037.jpg\n",
      "Processed 038.jpg\n",
      "Processed 039.jpg\n",
      "Processed 040.jpg\n",
      "Processed 041.jpg\n",
      "Processed 042.jpg\n",
      "Processed 043.jpg\n",
      "Processed 044.jpg\n",
      "Processed 045.jpg\n",
      "Processed 046.jpg\n",
      "Processed 047.jpg\n",
      "Processed 048.jpg\n",
      "Processed 049.jpg\n",
      "Processed 050.jpg\n",
      "Processed 051.jpg\n",
      "Processed 052.jpg\n",
      "Processed 053.jpg\n",
      "Processed 054.jpg\n",
      "Processed 055.jpg\n",
      "Processed 056.jpg\n",
      "Processed 057.jpg\n",
      "Processed 058.jpg\n",
      "Processed 059.jpg\n",
      "Processed 060.jpg\n",
      "Processed 061.jpg\n",
      "Processed 062.jpg\n",
      "Processed 063.jpg\n",
      "Processed 064.jpg\n",
      "Processed 065.jpg\n",
      "Processed 066.jpg\n",
      "Processed 067.jpg\n",
      "Processed 068.jpg\n",
      "Processed 069.jpg\n",
      "Processed 070.jpg\n",
      "Processed 071.jpg\n",
      "Processed 072.jpg\n",
      "Processed 073.jpg\n",
      "Processed 074.jpg\n",
      "Processed 075.jpg\n",
      "Processed 076.jpg\n",
      "Processed 077.jpg\n",
      "Processed 078.jpg\n",
      "Processed 079.jpg\n",
      "Processed 080.jpg\n",
      "Processed 081.jpg\n",
      "Processed 082.jpg\n",
      "Processed 083.jpg\n",
      "Processed 084.jpg\n",
      "Processed 085.jpg\n",
      "Processed 086.jpg\n",
      "Processed 087.jpg\n",
      "Processed 088.jpg\n",
      "Processed 089.jpg\n",
      "Processed 090.jpg\n",
      "Processed 091.jpg\n",
      "Processed 092.jpg\n",
      "Processed 093.jpg\n",
      "Processed 094.jpg\n",
      "Processed 095.jpg\n",
      "Processed 096.jpg\n",
      "Processed 097.jpg\n",
      "Processed 098.jpg\n",
      "Processed 099.jpg\n",
      "Processed 100.jpg\n",
      "Processed 101.jpg\n",
      "Processed 102.jpg\n",
      "Processed 103.jpg\n",
      "Processed 104.jpg\n",
      "Processed 105.jpg\n",
      "Processed 106.jpg\n",
      "Processed 107.jpg\n",
      "Processed 108.jpg\n",
      "Processed 109.jpg\n",
      "Processed 110.jpg\n",
      "Processed 111.jpg\n",
      "Processed 112.jpg\n",
      "Processed 113.jpg\n",
      "Processed 114.jpg\n",
      "Processed 115.jpg\n",
      "Processed 116.jpg\n",
      "Processed 117.jpg\n",
      "Processed 118.jpg\n",
      "Processed 119.jpg\n",
      "Processed 120.jpg\n",
      "Processed 121.jpg\n",
      "Processed 122.jpg\n",
      "Processed 123.jpg\n",
      "Processed 124.jpg\n",
      "Processed 125.jpg\n",
      "Processed 126.jpg\n",
      "Processed 127.jpg\n",
      "Processed 128.jpg\n",
      "Processed 129.jpg\n",
      "Processed 130.jpg\n",
      "Processed 131.jpg\n",
      "Processed 132.jpg\n",
      "Processed 133.jpg\n",
      "Processed 134.jpg\n",
      "Processed 135.jpg\n",
      "Processed 136.jpg\n",
      "Processed 137.jpg\n",
      "Processed 138.jpg\n",
      "Processed 139.jpg\n",
      "Processed 140.jpg\n",
      "Processed 141.jpg\n",
      "Processed 142.jpg\n",
      "Processed 143.jpg\n",
      "Processed 144.jpg\n",
      "Processed 145.jpg\n",
      "Processed 146.jpg\n",
      "Processed 147.jpg\n",
      "Processed 148.jpg\n",
      "Processed 149.jpg\n",
      "Processed 150.jpg\n",
      "Processed 151.jpg\n",
      "Processed 152.jpg\n",
      "Processed 153.jpg\n",
      "Processed 154.jpg\n",
      "Processed 155.jpg\n",
      "Processed 156.jpg\n",
      "Processed 157.jpg\n",
      "Processed 158.jpg\n",
      "Processed 159.jpg\n",
      "Processed 160.jpg\n",
      "Processed 161.jpg\n",
      "Processed 162.jpg\n",
      "Processed 163.jpg\n",
      "Processed 164.jpg\n",
      "Processed 165.jpg\n",
      "Processed 166.jpg\n",
      "Processed 167.jpg\n",
      "Processed 168.jpg\n",
      "Processed 169.jpg\n",
      "Processed 170.jpg\n",
      "Processed 171.jpg\n",
      "Processed 172.jpg\n",
      "Processed 173.jpg\n",
      "Processed 174.jpg\n",
      "Processed 175.jpg\n",
      "Processed 176.jpg\n",
      "Processed 177.jpg\n",
      "Processed 178.jpg\n",
      "Processed 179.jpg\n",
      "Processed 180.jpg\n",
      "Processed 181.jpg\n",
      "Processed 182.jpg\n",
      "Processed 183.jpg\n",
      "Processed 184.jpg\n",
      "Processed 185.jpg\n",
      "Processed 186.jpg\n",
      "Processed 187.jpg\n",
      "Processed 188.jpg\n",
      "Processed 189.jpg\n",
      "Processed 190.jpg\n",
      "Processed 191.jpg\n",
      "Processed 192.jpg\n",
      "Processed 193.jpg\n",
      "Processed 194.jpg\n",
      "Processed 195.jpg\n",
      "Processed 196.jpg\n",
      "Processed 197.jpg\n",
      "Processed 198.jpg\n",
      "Processed 199.jpg\n",
      "Processed 200.jpg\n",
      "Scanning set for mom\n",
      "Processed 001.jpg\n",
      "Processed 002.jpg\n",
      "Processed 003.jpg\n",
      "Processed 004.jpg\n",
      "Processed 005.jpg\n",
      "Processed 006.jpg\n",
      "Processed 007.jpg\n",
      "Processed 008.jpg\n",
      "Processed 009.jpg\n",
      "Processed 010.jpg\n",
      "Processed 011.jpg\n",
      "Processed 012.jpg\n",
      "Processed 013.jpg\n",
      "Processed 014.jpg\n",
      "Processed 015.jpg\n",
      "Processed 016.jpg\n",
      "Processed 017.jpg\n",
      "Processed 018.jpg\n",
      "Processed 019.jpg\n",
      "Processed 020.jpg\n",
      "Processed 021.jpg\n",
      "Processed 022.jpg\n",
      "Processed 023.jpg\n",
      "Processed 024.jpg\n",
      "Processed 025.jpg\n",
      "Processed 026.jpg\n",
      "Processed 027.jpg\n",
      "Processed 028.jpg\n",
      "Processed 029.jpg\n",
      "Processed 030.jpg\n",
      "Processed 031.jpg\n",
      "Processed 032.jpg\n",
      "Processed 033.jpg\n",
      "Processed 034.jpg\n",
      "Processed 035.jpg\n",
      "Processed 036.jpg\n",
      "Processed 037.jpg\n",
      "Processed 038.jpg\n",
      "Processed 039.jpg\n",
      "Processed 040.jpg\n",
      "Processed 041.jpg\n",
      "Processed 042.jpg\n",
      "Processed 043.jpg\n",
      "Processed 044.jpg\n",
      "Processed 045.jpg\n",
      "Processed 046.jpg\n",
      "Processed 047.jpg\n",
      "Processed 048.jpg\n",
      "Processed 049.jpg\n",
      "Processed 050.jpg\n",
      "Processed 051.jpg\n",
      "Processed 052.jpg\n",
      "Processed 053.jpg\n",
      "Processed 054.jpg\n",
      "Processed 055.jpg\n",
      "Processed 056.jpg\n",
      "Processed 057.jpg\n",
      "Processed 058.jpg\n",
      "Processed 059.jpg\n",
      "Processed 060.jpg\n",
      "Processed 061.jpg\n",
      "Processed 062.jpg\n",
      "Processed 063.jpg\n",
      "Processed 064.jpg\n",
      "Processed 065.jpg\n",
      "Processed 066.jpg\n",
      "Processed 067.jpg\n",
      "Processed 068.jpg\n",
      "Processed 069.jpg\n",
      "Processed 070.jpg\n",
      "Processed 071.jpg\n",
      "Processed 072.jpg\n",
      "Processed 073.jpg\n",
      "Processed 074.jpg\n",
      "Processed 075.jpg\n",
      "Processed 076.jpg\n",
      "Processed 077.jpg\n",
      "Processed 078.jpg\n",
      "Processed 079.jpg\n",
      "Processed 080.jpg\n",
      "Processed 081.jpg\n",
      "Processed 082.jpg\n",
      "Processed 083.jpg\n",
      "Processed 084.jpg\n",
      "Processed 085.jpg\n",
      "Processed 086.jpg\n",
      "Processed 087.jpg\n",
      "Processed 088.jpg\n",
      "Processed 089.jpg\n",
      "Processed 090.jpg\n",
      "Processed 091.jpg\n",
      "Processed 092.jpg\n",
      "Processed 093.jpg\n",
      "Processed 094.jpg\n",
      "Processed 095.jpg\n",
      "Processed 096.jpg\n",
      "Processed 097.jpg\n",
      "Processed 098.jpg\n",
      "Processed 099.jpg\n",
      "Processed 100.jpg\n",
      "Processed 101.jpg\n",
      "Processed 102.jpg\n",
      "Processed 103.jpg\n",
      "Processed 104.jpg\n",
      "Processed 105.jpg\n",
      "Processed 106.jpg\n",
      "Processed 107.jpg\n",
      "Processed 108.jpg\n",
      "Processed 109.jpg\n",
      "Processed 110.jpg\n",
      "Processed 111.jpg\n",
      "Processed 112.jpg\n",
      "Processed 113.jpg\n",
      "Processed 114.jpg\n",
      "Processed 115.jpg\n",
      "Processed 116.jpg\n",
      "Processed 117.jpg\n",
      "Processed 118.jpg\n",
      "Processed 119.jpg\n",
      "Processed 120.jpg\n",
      "Processed 121.jpg\n",
      "Processed 122.jpg\n",
      "Processed 123.jpg\n",
      "Processed 124.jpg\n",
      "Processed 125.jpg\n",
      "Processed 126.jpg\n",
      "Processed 127.jpg\n",
      "Processed 128.jpg\n",
      "Processed 129.jpg\n",
      "Processed 130.jpg\n",
      "Processed 131.jpg\n",
      "Processed 132.jpg\n",
      "Processed 133.jpg\n",
      "Processed 134.jpg\n",
      "Processed 135.jpg\n",
      "Processed 136.jpg\n",
      "Processed 137.jpg\n",
      "Processed 138.jpg\n",
      "Processed 139.jpg\n",
      "Processed 140.jpg\n",
      "Processed 141.jpg\n",
      "Processed 142.jpg\n",
      "Processed 143.jpg\n",
      "Processed 144.jpg\n",
      "Processed 145.jpg\n",
      "Processed 146.jpg\n",
      "Processed 147.jpg\n",
      "Processed 148.jpg\n",
      "Processed 149.jpg\n",
      "Processed 150.jpg\n",
      "Processed 151.jpg\n",
      "Processed 152.jpg\n",
      "Processed 153.jpg\n",
      "Processed 154.jpg\n",
      "Processed 155.jpg\n",
      "Processed 156.jpg\n",
      "Processed 157.jpg\n",
      "Processed 158.jpg\n",
      "Processed 159.jpg\n",
      "Processed 160.jpg\n",
      "Processed 161.jpg\n",
      "Processed 162.jpg\n",
      "Processed 163.jpg\n",
      "Processed 164.jpg\n",
      "Processed 165.jpg\n",
      "Processed 166.jpg\n",
      "Processed 167.jpg\n",
      "Processed 168.jpg\n",
      "Processed 169.jpg\n",
      "Processed 170.jpg\n",
      "Processed 171.jpg\n",
      "Processed 172.jpg\n",
      "Processed 173.jpg\n",
      "Processed 174.jpg\n",
      "Processed 175.jpg\n",
      "Processed 176.jpg\n",
      "Processed 177.jpg\n",
      "Processed 178.jpg\n",
      "Processed 179.jpg\n",
      "Processed 180.jpg\n",
      "Processed 181.jpg\n",
      "Processed 182.jpg\n",
      "Processed 183.jpg\n",
      "Processed 184.jpg\n",
      "Processed 185.jpg\n",
      "Processed 186.jpg\n",
      "Processed 187.jpg\n",
      "Processed 188.jpg\n",
      "Processed 189.jpg\n",
      "Processed 190.jpg\n",
      "Processed 191.jpg\n",
      "Processed 192.jpg\n",
      "Processed 193.jpg\n",
      "Processed 194.jpg\n",
      "Processed 195.jpg\n",
      "Processed 196.jpg\n",
      "Processed 197.jpg\n",
      "Processed 198.jpg\n",
      "Processed 199.jpg\n",
      "Processed 200.jpg\n",
      "Finished scanning images with all models\n"
     ]
    }
   ],
   "source": [
    "def detect_dad():\n",
    "    print(\"Scanning set for dad\")\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(\"dad_cnn.pth\"))\n",
    "    model.eval()\n",
    "    detect_faces_best_aspect_ratios(test_data, model, 'dad', cluster_train_data, task=\"task2\")\n",
    "\n",
    "def detect_deedee():\n",
    "    print(\"Scanning set for deedee\")\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(\"deedee_cnn.pth\"))\n",
    "    model.eval()\n",
    "    detect_faces_best_aspect_ratios(test_data, model, 'deedee', cluster_train_data, task=\"task2\")\n",
    "\n",
    "def detect_dexter():\n",
    "    print(\"Scanning set for dexter\")\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(\"dexter_cnn.pth\"))\n",
    "    model.eval()\n",
    "    detect_faces_best_aspect_ratios(test_data, model, 'dexter', cluster_train_data, task=\"task2\")\n",
    "\n",
    "def detect_mom():\n",
    "    print(\"Scanning set for mom\")\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(\"mom_cnn.pth\"))\n",
    "    model.eval()\n",
    "    detect_faces_best_aspect_ratios(test_data, model, 'mom', cluster_train_data, task=\"task2\")\n",
    "\n",
    "detect_dad()\n",
    "detect_deedee()\n",
    "detect_dexter()\n",
    "detect_mom()\n",
    "print(\"Finished scanning images with all models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
